//! CUDA Code Generation
//!
//! Generates CUDA C++ code from MIR functions, including kernel code,
//! host code, and memory management.

use std::collections::HashMap;
use std::fmt::Write;

use super::kernel::{Dim3, KernelAnalyzer, KernelConfig, KernelInfo, LaunchBounds};
use super::memory::{MemoryPlan, MemoryPlanner, SharedMemoryAlloc};
use super::tensor_core::TensorCoreConfig;
use super::types::{AddressSpace, CudaType, GpuArch};
use crate::mir::block::{BasicBlock, Terminator};
use crate::mir::function::MirFunction;
use crate::mir::inst::{FloatPredicate, IntPredicate, Operation};
use crate::mir::module::{ConstValue, MirModule};
use crate::mir::types::MirType;
use crate::mir::value::ValueId;

/// Result type for CUDA code generation
pub type CudaResult<T> = Result<T, CudaError>;

/// Errors during CUDA code generation
#[derive(Clone, Debug, PartialEq)]
pub enum CudaError {
    /// Unsupported operation for GPU
    UnsupportedOperation { op: String, reason: String },
    /// Architecture doesn't support feature
    UnsupportedFeature { feature: String, arch: GpuArch },
    /// Resource limit exceeded
    ResourceLimit {
        resource: String,
        limit: usize,
        required: usize,
    },
    /// Invalid kernel configuration
    InvalidConfig { message: String },
    /// Type conversion error
    TypeConversion { mir_type: String, reason: String },
    /// Internal error
    Internal { message: String },
}

impl std::fmt::Display for CudaError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            CudaError::UnsupportedOperation { op, reason } => {
                write!(f, "Unsupported operation '{}': {}", op, reason)
            }
            CudaError::UnsupportedFeature { feature, arch } => {
                write!(f, "Feature '{}' not supported on {:?}", feature, arch)
            }
            CudaError::ResourceLimit {
                resource,
                limit,
                required,
            } => {
                write!(
                    f,
                    "{} limit exceeded: {} required, {} available",
                    resource, required, limit
                )
            }
            CudaError::InvalidConfig { message } => {
                write!(f, "Invalid configuration: {}", message)
            }
            CudaError::TypeConversion { mir_type, reason } => {
                write!(f, "Cannot convert type '{}': {}", mir_type, reason)
            }
            CudaError::Internal { message } => {
                write!(f, "Internal error: {}", message)
            }
        }
    }
}

impl std::error::Error for CudaError {}

/// Generated CUDA module
#[derive(Clone, Debug)]
pub struct CudaModule {
    /// Module name
    pub name: String,
    /// Include statements
    pub includes: Vec<String>,
    /// Type definitions
    pub type_defs: Vec<String>,
    /// Constant definitions
    pub constants: Vec<String>,
    /// Device functions
    pub device_functions: Vec<String>,
    /// Kernel functions
    pub kernels: Vec<CudaKernel>,
    /// Host functions
    pub host_functions: Vec<String>,
    /// Kernel metadata
    pub kernel_info: HashMap<String, KernelInfo>,
}

impl CudaModule {
    pub fn new(name: String) -> Self {
        Self {
            name,
            includes: vec![
                "#include <cuda_runtime.h>".to_string(),
                "#include <cuda_fp16.h>".to_string(),
                "#include <mma.h>".to_string(),
                "#include <cstdint>".to_string(),
            ],
            type_defs: Vec::new(),
            constants: Vec::new(),
            device_functions: Vec::new(),
            kernels: Vec::new(),
            host_functions: Vec::new(),
            kernel_info: HashMap::new(),
        }
    }

    /// Generate complete CUDA source code
    pub fn to_cuda_source(&self) -> String {
        let mut code = String::new();

        // Header comment
        writeln!(code, "// Generated by MedLang CUDA backend").unwrap();
        writeln!(code, "// Module: {}", self.name).unwrap();
        writeln!(code).unwrap();

        // Includes
        for inc in &self.includes {
            writeln!(code, "{}", inc).unwrap();
        }
        writeln!(code).unwrap();

        // WMMA namespace
        writeln!(code, "using namespace nvcuda;").unwrap();
        writeln!(code).unwrap();

        // Type definitions
        if !self.type_defs.is_empty() {
            writeln!(code, "// Type definitions").unwrap();
            for typedef in &self.type_defs {
                writeln!(code, "{}", typedef).unwrap();
            }
            writeln!(code).unwrap();
        }

        // Constants
        if !self.constants.is_empty() {
            writeln!(code, "// Constants").unwrap();
            for constant in &self.constants {
                writeln!(code, "{}", constant).unwrap();
            }
            writeln!(code).unwrap();
        }

        // Device functions
        if !self.device_functions.is_empty() {
            writeln!(code, "// Device functions").unwrap();
            for func in &self.device_functions {
                writeln!(code, "{}", func).unwrap();
                writeln!(code).unwrap();
            }
        }

        // Kernels
        writeln!(code, "// Kernels").unwrap();
        for kernel in &self.kernels {
            writeln!(code, "{}", kernel.source).unwrap();
            writeln!(code).unwrap();
        }

        // Host functions
        if !self.host_functions.is_empty() {
            writeln!(code, "// Host functions").unwrap();
            for func in &self.host_functions {
                writeln!(code, "{}", func).unwrap();
                writeln!(code).unwrap();
            }
        }

        code
    }
}

/// Generated CUDA kernel
#[derive(Clone, Debug)]
pub struct CudaKernel {
    /// Kernel name
    pub name: String,
    /// Complete kernel source code
    pub source: String,
    /// Kernel configuration
    pub config: KernelConfig,
    /// Memory plan
    pub memory_plan: MemoryPlan,
}

/// CUDA code generator
pub struct CudaCodegen {
    /// Target architecture
    arch: GpuArch,
    /// Kernel analyzer
    analyzer: KernelAnalyzer,
    /// Memory planner
    memory_planner: MemoryPlanner,
    /// Value to register/variable mapping
    value_names: HashMap<ValueId, String>,
    /// Next temporary variable number
    temp_counter: u32,
    /// Current indentation level
    indent: usize,
}

impl CudaCodegen {
    pub fn new(arch: GpuArch) -> Self {
        Self {
            arch,
            analyzer: KernelAnalyzer::new(arch),
            memory_planner: MemoryPlanner::new(arch),
            value_names: HashMap::new(),
            temp_counter: 0,
            indent: 0,
        }
    }

    /// Generate CUDA module from MIR module
    pub fn generate_module(&mut self, module: &MirModule) -> CudaResult<CudaModule> {
        let mut cuda_module = CudaModule::new(module.name.clone());

        // Generate type definitions
        for typedef in &module.types {
            let cuda_typedef = self.generate_typedef(&typedef.name, &typedef.ty)?;
            cuda_module.type_defs.push(cuda_typedef);
        }

        // Generate constants
        for constant in &module.constants {
            let cuda_const =
                self.generate_constant(&constant.name, &constant.ty, &constant.value)?;
            cuda_module.constants.push(cuda_const);
        }

        // Generate kernels from functions marked for GPU
        for func in &module.functions {
            if self.should_generate_kernel(func) {
                let kernel = self.generate_kernel(func)?;
                cuda_module
                    .kernel_info
                    .insert(kernel.name.clone(), KernelInfo::new(kernel.name.clone()));
                cuda_module.kernels.push(kernel);

                // Generate host wrapper
                let wrapper = self.generate_host_wrapper(func)?;
                cuda_module.host_functions.push(wrapper);
            }
        }

        Ok(cuda_module)
    }

    /// Check if function should be compiled as kernel
    /// For now, we generate kernels for all functions in a GPU module
    fn should_generate_kernel(&self, _func: &MirFunction) -> bool {
        // In the future, check func.attributes for GPU-specific flags
        // For now, assume all functions in a CUDA module are kernels
        true
    }

    /// Generate CUDA kernel from MIR function
    pub fn generate_kernel(&mut self, func: &MirFunction) -> CudaResult<CudaKernel> {
        // Reset state
        self.value_names.clear();
        self.temp_counter = 0;
        self.indent = 0;

        // Analyze kernel
        let analysis = self.analyzer.analyze(func);
        let config = analysis.suggested_config.clone();
        let memory_plan = self
            .memory_planner
            .plan_reduction(config.threads_per_block() as usize, CudaType::Float);

        let mut code = String::new();

        // Generate kernel signature
        let launch_bounds = LaunchBounds::new(config.threads_per_block() as u32);
        write!(code, "{} ", launch_bounds.to_cuda_attribute()).unwrap();
        writeln!(code, "__global__ void {}(", func.name).unwrap();

        // Parameters
        let params: Vec<String> = func
            .signature
            .params
            .iter()
            .enumerate()
            .map(|(i, ty)| {
                let name = func
                    .signature
                    .param_names
                    .get(i)
                    .cloned()
                    .unwrap_or_else(|| format!("arg{}", i));
                let cuda_type = CudaType::from_mir(ty);
                format!("\t{} {}", cuda_type.cuda_name(), name)
            })
            .collect();
        writeln!(code, "{})", params.join(",\n")).unwrap();

        // Kernel body
        writeln!(code, "{{").unwrap();
        self.indent = 1;

        // Thread indices
        self.write_indent(&mut code);
        writeln!(
            code,
            "const int tid = threadIdx.x + blockIdx.x * blockDim.x;"
        )
        .unwrap();
        self.write_indent(&mut code);
        writeln!(code, "const int lane = threadIdx.x % 32;").unwrap();
        self.write_indent(&mut code);
        writeln!(code, "const int warp = threadIdx.x / 32;").unwrap();
        writeln!(code).unwrap();

        // Shared memory declarations
        let shared_decls = memory_plan.generate_shared_decls();
        if !shared_decls.is_empty() {
            self.write_indent(&mut code);
            writeln!(code, "// Shared memory").unwrap();
            for line in shared_decls.lines() {
                self.write_indent(&mut code);
                writeln!(code, "{}", line).unwrap();
            }
            writeln!(code).unwrap();
        }

        // Map parameters to value names
        if let Some(entry_block) = func.entry_block() {
            for (i, param) in entry_block.params.iter().enumerate() {
                let name = func
                    .signature
                    .param_names
                    .get(i)
                    .cloned()
                    .unwrap_or_else(|| format!("arg{}", i));
                self.value_names.insert(param.value, name);
            }
        }

        // Generate basic blocks
        for (block_idx, block) in func.blocks.iter().enumerate() {
            self.generate_block(&mut code, block, block_idx == 0)?;
        }

        writeln!(code, "}}").unwrap();

        Ok(CudaKernel {
            name: func.name.clone(),
            source: code,
            config,
            memory_plan,
        })
    }

    /// Generate code for a basic block
    fn generate_block(
        &mut self,
        code: &mut String,
        block: &BasicBlock,
        is_entry: bool,
    ) -> CudaResult<()> {
        // Block label (skip for entry block)
        if !is_entry {
            let label = block
                .name
                .as_ref()
                .map(|n| n.clone())
                .unwrap_or_else(|| format!("block_{}", block.id.0));
            writeln!(code, "{}:", label).unwrap();
        }

        // Block parameters (not for entry block)
        if !is_entry {
            for param in &block.params {
                let name = self.get_or_create_name(param.value);
                let ty = CudaType::from_mir(&param.ty);
                self.write_indent(code);
                writeln!(code, "{} {};", ty.cuda_name(), name).unwrap();
            }
        }

        // Instructions
        for inst in &block.instructions {
            self.generate_instruction(code, inst)?;
        }

        // Terminator
        self.generate_terminator(code, &block.terminator)?;

        Ok(())
    }

    /// Generate code for an instruction
    fn generate_instruction(
        &mut self,
        code: &mut String,
        inst: &crate::mir::inst::Instruction,
    ) -> CudaResult<()> {
        let result_name = inst.result.map(|v| self.get_or_create_name(v));
        let result_type = CudaType::from_mir(&inst.ty);

        self.write_indent(code);

        match &inst.op {
            // Arithmetic
            Operation::FAdd { lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} + {};",
                        result_type.cuda_name(),
                        name,
                        lhs_name,
                        rhs_name
                    )
                    .unwrap();
                }
            }
            Operation::FSub { lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} - {};",
                        result_type.cuda_name(),
                        name,
                        lhs_name,
                        rhs_name
                    )
                    .unwrap();
                }
            }
            Operation::FMul { lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} * {};",
                        result_type.cuda_name(),
                        name,
                        lhs_name,
                        rhs_name
                    )
                    .unwrap();
                }
            }
            Operation::FDiv { lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} / {};",
                        result_type.cuda_name(),
                        name,
                        lhs_name,
                        rhs_name
                    )
                    .unwrap();
                }
            }
            Operation::FNeg { operand } => {
                let op_name = self.get_value_name(*operand);
                if let Some(name) = result_name {
                    writeln!(code, "{} {} = -{};", result_type.cuda_name(), name, op_name).unwrap();
                }
            }

            // Integer arithmetic
            Operation::IAdd { lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} + {};",
                        result_type.cuda_name(),
                        name,
                        lhs_name,
                        rhs_name
                    )
                    .unwrap();
                }
            }
            Operation::ISub { lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} - {};",
                        result_type.cuda_name(),
                        name,
                        lhs_name,
                        rhs_name
                    )
                    .unwrap();
                }
            }
            Operation::IMul { lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} * {};",
                        result_type.cuda_name(),
                        name,
                        lhs_name,
                        rhs_name
                    )
                    .unwrap();
                }
            }
            Operation::IDiv { lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} / {};",
                        result_type.cuda_name(),
                        name,
                        lhs_name,
                        rhs_name
                    )
                    .unwrap();
                }
            }

            // FMA
            Operation::FMA { a, b, c } => {
                let a_name = self.get_value_name(*a);
                let b_name = self.get_value_name(*b);
                let c_name = self.get_value_name(*c);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = fma({}, {}, {});",
                        result_type.cuda_name(),
                        name,
                        a_name,
                        b_name,
                        c_name
                    )
                    .unwrap();
                }
            }

            // Transcendental
            Operation::Sqrt { operand } => {
                let op_name = self.get_value_name(*operand);
                if let Some(name) = result_name {
                    let func = if matches!(result_type, CudaType::Float) {
                        "sqrtf"
                    } else {
                        "sqrt"
                    };
                    writeln!(
                        code,
                        "{} {} = {}({});",
                        result_type.cuda_name(),
                        name,
                        func,
                        op_name
                    )
                    .unwrap();
                }
            }
            Operation::Exp { operand } => {
                let op_name = self.get_value_name(*operand);
                if let Some(name) = result_name {
                    let func = if matches!(result_type, CudaType::Float) {
                        "expf"
                    } else {
                        "exp"
                    };
                    writeln!(
                        code,
                        "{} {} = {}({});",
                        result_type.cuda_name(),
                        name,
                        func,
                        op_name
                    )
                    .unwrap();
                }
            }
            Operation::Log { operand } => {
                let op_name = self.get_value_name(*operand);
                if let Some(name) = result_name {
                    let func = if matches!(result_type, CudaType::Float) {
                        "logf"
                    } else {
                        "log"
                    };
                    writeln!(
                        code,
                        "{} {} = {}({});",
                        result_type.cuda_name(),
                        name,
                        func,
                        op_name
                    )
                    .unwrap();
                }
            }
            Operation::Sin { operand } => {
                let op_name = self.get_value_name(*operand);
                if let Some(name) = result_name {
                    let func = if matches!(result_type, CudaType::Float) {
                        "sinf"
                    } else {
                        "sin"
                    };
                    writeln!(
                        code,
                        "{} {} = {}({});",
                        result_type.cuda_name(),
                        name,
                        func,
                        op_name
                    )
                    .unwrap();
                }
            }
            Operation::Cos { operand } => {
                let op_name = self.get_value_name(*operand);
                if let Some(name) = result_name {
                    let func = if matches!(result_type, CudaType::Float) {
                        "cosf"
                    } else {
                        "cos"
                    };
                    writeln!(
                        code,
                        "{} {} = {}({});",
                        result_type.cuda_name(),
                        name,
                        func,
                        op_name
                    )
                    .unwrap();
                }
            }
            Operation::Tanh { operand } => {
                let op_name = self.get_value_name(*operand);
                if let Some(name) = result_name {
                    let func = if matches!(result_type, CudaType::Float) {
                        "tanhf"
                    } else {
                        "tanh"
                    };
                    writeln!(
                        code,
                        "{} {} = {}({});",
                        result_type.cuda_name(),
                        name,
                        func,
                        op_name
                    )
                    .unwrap();
                }
            }
            Operation::Pow { base, exp } => {
                let base_name = self.get_value_name(*base);
                let exp_name = self.get_value_name(*exp);
                if let Some(name) = result_name {
                    let func = if matches!(result_type, CudaType::Float) {
                        "powf"
                    } else {
                        "pow"
                    };
                    writeln!(
                        code,
                        "{} {} = {}({}, {});",
                        result_type.cuda_name(),
                        name,
                        func,
                        base_name,
                        exp_name
                    )
                    .unwrap();
                }
            }

            // Constants
            Operation::ConstFloat { value, ty } => {
                if let Some(name) = result_name {
                    let suffix = if matches!(CudaType::from_mir(ty), CudaType::Float) {
                        "f"
                    } else {
                        ""
                    };
                    writeln!(
                        code,
                        "{} {} = {}{};",
                        result_type.cuda_name(),
                        name,
                        value,
                        suffix
                    )
                    .unwrap();
                }
            }
            Operation::ConstInt { value, ty } => {
                if let Some(name) = result_name {
                    writeln!(code, "{} {} = {};", result_type.cuda_name(), name, value).unwrap();
                }
            }

            // Memory operations
            Operation::Load {
                ptr,
                ty: _,
                volatile: _,
                align: _,
            } => {
                let ptr_name = self.get_value_name(*ptr);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = *{};",
                        result_type.cuda_name(),
                        name,
                        ptr_name
                    )
                    .unwrap();
                }
            }
            Operation::Store {
                ptr,
                value,
                volatile: _,
                align: _,
            } => {
                let ptr_name = self.get_value_name(*ptr);
                let val_name = self.get_value_name(*value);
                writeln!(code, "*{} = {};", ptr_name, val_name).unwrap();
            }

            // Comparisons
            Operation::FCmp { pred, lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                let op_str = float_pred_to_str(pred);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "bool {} = {} {} {};",
                        name, lhs_name, op_str, rhs_name
                    )
                    .unwrap();
                }
            }
            Operation::ICmp { pred, lhs, rhs } => {
                let lhs_name = self.get_value_name(*lhs);
                let rhs_name = self.get_value_name(*rhs);
                let op_str = int_pred_to_str(pred);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "bool {} = {} {} {};",
                        name, lhs_name, op_str, rhs_name
                    )
                    .unwrap();
                }
            }

            // Select (ternary)
            Operation::Select {
                cond,
                then_val,
                else_val,
            } => {
                let cond_name = self.get_value_name(*cond);
                let then_name = self.get_value_name(*then_val);
                let else_name = self.get_value_name(*else_val);
                if let Some(name) = result_name {
                    writeln!(
                        code,
                        "{} {} = {} ? {} : {};",
                        result_type.cuda_name(),
                        name,
                        cond_name,
                        then_name,
                        else_name
                    )
                    .unwrap();
                }
            }

            // Tensor core operations would be handled here when WMMA ops are added to MIR
            // For now, they are generated directly via the tensor_core module

            // Synchronization - use fence for now
            Operation::Fence { .. } => {
                writeln!(code, "__syncthreads();").unwrap();
            }

            // Default case
            _ => {
                writeln!(code, "// Unsupported operation: {:?}", inst.op).unwrap();
            }
        }

        Ok(())
    }

    /// Generate code for terminator
    fn generate_terminator(&mut self, code: &mut String, term: &Terminator) -> CudaResult<()> {
        match term {
            Terminator::Return { value } => {
                self.write_indent(code);
                if let Some(val) = value {
                    let val_name = self.get_value_name(*val);
                    writeln!(code, "return {};", val_name).unwrap();
                } else {
                    writeln!(code, "return;").unwrap();
                }
            }
            Terminator::Goto { target, args } => {
                // Pass arguments (in real code, these would be assigned to block params)
                for (i, arg) in args.iter().enumerate() {
                    self.write_indent(code);
                    let arg_name = self.get_value_name(*arg);
                    writeln!(code, "// block param {} = {};", i, arg_name).unwrap();
                }
                self.write_indent(code);
                writeln!(code, "goto block_{};", target.0).unwrap();
            }
            Terminator::Branch {
                cond,
                then_block,
                then_args,
                else_block,
                else_args,
            } => {
                let cond_name = self.get_value_name(*cond);
                self.write_indent(code);
                writeln!(code, "if ({}) {{", cond_name).unwrap();
                self.indent += 1;
                self.write_indent(code);
                writeln!(code, "goto block_{};", then_block.0).unwrap();
                self.indent -= 1;
                self.write_indent(code);
                writeln!(code, "}} else {{").unwrap();
                self.indent += 1;
                self.write_indent(code);
                writeln!(code, "goto block_{};", else_block.0).unwrap();
                self.indent -= 1;
                self.write_indent(code);
                writeln!(code, "}}").unwrap();
            }
            Terminator::Unreachable => {
                self.write_indent(code);
                writeln!(code, "__builtin_unreachable();").unwrap();
            }
            _ => {
                self.write_indent(code);
                writeln!(code, "// Unhandled terminator").unwrap();
            }
        }
        Ok(())
    }

    /// Generate host wrapper function
    fn generate_host_wrapper(&self, func: &MirFunction) -> CudaResult<String> {
        let mut code = String::new();

        writeln!(code, "void launch_{}(", func.name).unwrap();

        // Parameters
        let params: Vec<String> = func
            .signature
            .params
            .iter()
            .enumerate()
            .map(|(i, ty)| {
                let name = func
                    .signature
                    .param_names
                    .get(i)
                    .cloned()
                    .unwrap_or_else(|| format!("arg{}", i));
                let cuda_type = CudaType::from_mir(ty);
                format!("\t{} {}", cuda_type.cuda_name(), name)
            })
            .collect();

        // Add grid/block config parameters
        let mut all_params = params;
        all_params.push("\tdim3 grid".to_string());
        all_params.push("\tdim3 block".to_string());
        all_params.push("\tcudaStream_t stream = 0".to_string());

        writeln!(code, "{})", all_params.join(",\n")).unwrap();
        writeln!(code, "{{").unwrap();

        // Kernel launch
        let args: Vec<String> = func
            .signature
            .param_names
            .iter()
            .enumerate()
            .map(|(i, name)| name.clone())
            .collect();

        writeln!(
            code,
            "\t{}<<<grid, block, 0, stream>>>({});",
            func.name,
            args.join(", ")
        )
        .unwrap();

        writeln!(code, "}}").unwrap();

        Ok(code)
    }

    /// Generate type definition
    fn generate_typedef(&self, name: &str, ty: &MirType) -> CudaResult<String> {
        let cuda_type = CudaType::from_mir(ty);
        Ok(format!("typedef {} {};", cuda_type.cuda_name(), name))
    }

    /// Generate constant definition
    fn generate_constant(
        &self,
        name: &str,
        ty: &MirType,
        value: &ConstValue,
    ) -> CudaResult<String> {
        let cuda_type = CudaType::from_mir(ty);
        let value_str = match value {
            ConstValue::Int(v) => format!("{}", v),
            ConstValue::Float(v) => format!("{}", v),
            ConstValue::Bool(v) => {
                if *v {
                    "true".to_string()
                } else {
                    "false".to_string()
                }
            }
            ConstValue::String(s) => format!("\"{}\"", s),
            ConstValue::Null => "nullptr".to_string(),
            ConstValue::Zero => "0".to_string(),
            ConstValue::Undef => "/* undef */".to_string(),
            ConstValue::Array(_) | ConstValue::Struct(_) => {
                return Err(CudaError::UnsupportedOperation {
                    op: "complex constant".to_string(),
                    reason: "Array and struct constants not yet supported".to_string(),
                });
            }
        };
        Ok(format!(
            "__constant__ {} {} = {};",
            cuda_type.cuda_name(),
            name,
            value_str
        ))
    }

    /// Get or create variable name for value
    fn get_or_create_name(&mut self, value: ValueId) -> String {
        if let Some(name) = self.value_names.get(&value) {
            return name.clone();
        }
        let name = format!("t{}", self.temp_counter);
        self.temp_counter += 1;
        self.value_names.insert(value, name.clone());
        name
    }

    /// Get variable name for value
    fn get_value_name(&self, value: ValueId) -> String {
        self.value_names
            .get(&value)
            .cloned()
            .unwrap_or_else(|| format!("v{}", value.0))
    }

    /// Write indentation
    fn write_indent(&self, code: &mut String) {
        for _ in 0..self.indent {
            code.push('\t');
        }
    }
}

/// Convert comparison operator to CUDA string
/// Convert integer comparison predicate to CUDA string
fn int_pred_to_str(pred: &IntPredicate) -> &'static str {
    match pred {
        IntPredicate::Eq => "==",
        IntPredicate::Ne => "!=",
        IntPredicate::Slt | IntPredicate::Ult => "<",
        IntPredicate::Sle | IntPredicate::Ule => "<=",
        IntPredicate::Sgt | IntPredicate::Ugt => ">",
        IntPredicate::Sge | IntPredicate::Uge => ">=",
    }
}

/// Convert float comparison predicate to CUDA string
fn float_pred_to_str(pred: &FloatPredicate) -> &'static str {
    match pred {
        FloatPredicate::OEq | FloatPredicate::UEq => "==",
        FloatPredicate::ONe | FloatPredicate::UNe => "!=",
        FloatPredicate::OLt | FloatPredicate::ULt => "<",
        FloatPredicate::OLe | FloatPredicate::ULe => "<=",
        FloatPredicate::OGt | FloatPredicate::UGt => ">",
        FloatPredicate::OGe | FloatPredicate::UGe => ">=",
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::mir::block::Terminator;
    use crate::mir::function::{FunctionBuilder, FunctionSignature};
    use crate::mir::inst::Operation;

    #[test]
    fn test_cuda_module_generation() {
        let module = CudaModule::new("test_module".to_string());
        let source = module.to_cuda_source();

        assert!(source.contains("#include <cuda_runtime.h>"));
        assert!(source.contains("Generated by MedLang"));
    }

    #[test]
    fn test_simple_kernel_generation() {
        let sig = FunctionSignature::new(
            vec![
                MirType::ptr(MirType::F32, true),
                MirType::ptr(MirType::F32, false),
                MirType::I32,
            ],
            MirType::Void,
        );
        let mut builder = FunctionBuilder::new("vector_add", sig);

        builder.terminate(Terminator::Return { value: None });
        let func = builder.build();

        let mut codegen = CudaCodegen::new(GpuArch::Sm80);
        let kernel = codegen.generate_kernel(&func).unwrap();

        assert!(kernel.source.contains("__global__"));
        assert!(kernel.source.contains("vector_add"));
        assert!(kernel.source.contains("threadIdx"));
    }

    #[test]
    fn test_arithmetic_codegen() {
        let sig = FunctionSignature::new(vec![MirType::F32, MirType::F32], MirType::F32);
        let mut builder = FunctionBuilder::new("add_kernel", sig);

        let a = builder.param(0).unwrap();
        let b = builder.param(1).unwrap();
        let sum = builder.push_op(Operation::FAdd { lhs: a, rhs: b }, MirType::F32);

        builder.terminate(Terminator::Return { value: Some(sum) });
        let func = builder.build();

        let mut codegen = CudaCodegen::new(GpuArch::Sm80);
        let kernel = codegen.generate_kernel(&func).unwrap();

        assert!(kernel.source.contains("+"));
    }

    #[test]
    fn test_launch_bounds() {
        let bounds = LaunchBounds::new(512).with_min_blocks(2);
        assert_eq!(bounds.to_cuda_attribute(), "__launch_bounds__(512, 2)");
    }

    #[test]
    fn test_int_pred_str() {
        assert_eq!(int_pred_to_str(&IntPredicate::Eq), "==");
        assert_eq!(int_pred_to_str(&IntPredicate::Slt), "<");
        assert_eq!(int_pred_to_str(&IntPredicate::Sge), ">=");
    }

    #[test]
    fn test_float_pred_str() {
        assert_eq!(float_pred_to_str(&FloatPredicate::OEq), "==");
        assert_eq!(float_pred_to_str(&FloatPredicate::OLt), "<");
        assert_eq!(float_pred_to_str(&FloatPredicate::OGe), ">=");
    }
}
